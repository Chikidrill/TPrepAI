from docx import Document
import openai
import random
import json
import nltk
import logging
import tiktoken
from fastapi import FastAPI, UploadFile, File, HTTPException
import shutil
import os
from dotenv import load_dotenv
import fitz
import pytesseract
from pdf2image import convert_from_path
from fastapi.middleware.cors import CORSMiddleware

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

load_dotenv()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
openai.api_key = os.getenv("OPENAI_API_KEY")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
ENCODER = tiktoken.encoding_for_model("gpt-4o-mini")


def count_tokens(text):
    return len(ENCODER.encode(text))


# –§–∏–ª—å—Ç—Ä –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
def remove_duplicates(questions):
    unique_questions = []
    seen_questions = set()
    for q in questions:
        if q["question"] not in seen_questions:
            unique_questions.append(q)
            seen_questions.add(q["question"])
    return unique_questions


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞, –≤–∫–ª—é—á–∞—è —Ç–µ–≥–∏
def parse_questions(text):
    lines = text.split("\n")
    questions = []
    current_question = None

    for line in lines:
        line = line.strip()  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã

        if not line:
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏

        if line.endswith("?"):  # –ï—Å–ª–∏ —ç—Ç–æ –≤–æ–ø—Ä–æ—Å
            if current_question:
                questions.append(current_question)
            current_question = {"question": line, "answers": [], "tags": []}
        elif current_question:
            if line.startswith("–¢–µ–≥–∏:"):
                current_question["tags"] = [tag.strip() for tag in line.replace("–¢–µ–≥–∏:", "").split(",")]
            else:
                current_question["answers"].append(line.strip())

    if current_question:
        questions.append(current_question)

    # üîπ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    for q in questions:
        if not q["answers"]:  # –ï—Å–ª–∏ —É –≤–æ–ø—Ä–æ—Å–∞ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ–≥–æ
            correct_answer, wrong_answers = generate_answers(q["question"], q["tags"])
            q["answers"] = [" ".join(correct_answer.strip().splitlines())]  # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            q["wrong_answers"] = list(set(" ".join(ans.strip().splitlines()) for ans in wrong_answers if ans.strip()))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏, —Å–æ–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏
            logging.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç: {q['question']} -> {q['answers'][0]} | {q['wrong_answers']}")
        else:
            correct_answer = " ".join(q["answers"]).strip().replace("\n", " ")  # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            wrong_answers = generate_wrong_answers(q["question"], correct_answer, q["tags"])
            q["answers"] = [correct_answer]  # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            q["wrong_answers"] = list(set(" ".join(ans.strip().splitlines()) for ans in wrong_answers if ans.strip()))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏, —Å–æ–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏
            logging.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ—Ç–≤–µ—Ç: {q['question']} -> {q['answers'][0]} | {q['wrong_answers']}")

    logging.debug(f"DEBUG (—Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏):\n{json.dumps(questions, indent=4, ensure_ascii=False)}")

    return remove_duplicates(questions)


def generate_answers(question, tags):
    try:
        prompt = f"""
–í–æ–ø—Ä–æ—Å: {question}
–¢–µ–≥–∏: {', '.join(tags) if tags else '–Ω–µ—Ç'}
–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 1 –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏ 3 –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã—Ö, –Ω–æ –Ω–µ–≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–∞. 
–û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–µ—Ç–∫–∏–º–∏, –æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–º–∏.
–§–æ—Ä–º–∞—Ç:
–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π: [—Ç–µ–∫—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞]
–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ: [–æ—Ç–≤–µ—Ç 1], [–æ—Ç–≤–µ—Ç 2], [–æ—Ç–≤–µ—Ç 3]
        """

        if count_tokens(prompt) > 4096:
            logging.error("–û—à–∏–±–∫–∞: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π!")
            return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", ["–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 1", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 2", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3"]

        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ—Å—Ç–æ–≤. –ü—Ä–∏–¥—É–º–∞–π 1 –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏ 3 –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–∞."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )

        content = response.choices[0].message.content.strip()
        lines = content.split("\n")

        correct_answer = lines[0].replace("–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π: ", "").strip()
        wrong_answers = [ans.strip() for ans in lines[1].replace("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ: ", "").split(",")]

        if len(wrong_answers) < 3:
            wrong_answers = ["–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 1", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 2", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3"]

        return correct_answer, wrong_answers
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤: {e}")
        return "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏", ["–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 1", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 2", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3"]


# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ —Å OpenAI API (—É—á–µ—Ç —Ç–µ–≥–æ–≤)
def generate_wrong_answers(question, correct_answer, tags):
    try:
        prompt = f"–í–æ–ø—Ä–æ—Å: {question}\n–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {correct_answer}\n–¢–µ–≥–∏: {', '.join(tags)}\n–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 3 –Ω–µ–≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–∞, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Ç–µ–º–æ–π:"

        if count_tokens(prompt) > 4096:
            logging.error("–û—à–∏–±–∫–∞: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π!")
            return ["–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 1", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 2", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3"]

        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ—Å—Ç–æ–≤. –°–æ–∑–¥–∞–π 3 –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω—ã—Ö, –Ω–æ –Ω–µ–≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–∞."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )

        wrong_answers = response.choices[0].message.content.strip().split("\n")
        return wrong_answers if len(wrong_answers) >= 3 else ["–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 1", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 2",
                                                              "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3"]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ–≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {e}")
        return ["–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 1", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 2", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ 3"]


def read_docx(file_path):
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ .docx —Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –∫–∞–∫ —Å—Ç—Ä–æ–∫—É."""
    doc = Document(file_path)
    text = "\n".join([para.text for para in doc.paragraphs])
    return text


def read_pdf(file_path):
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF-—Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –∫–∞–∫ —Å—Ç—Ä–æ–∫—É."""
    doc = fitz.open(file_path)
    text = "\n".join([page.get_text() for page in doc])
    return text


def read_pdf_with_ocr(file_path):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç OCR –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞."""
    images = convert_from_path(file_path)  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text = "\n".join([pytesseract.image_to_string(img, lang="rus+eng") for img in images])  # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ç–µ–∫—Å—Ç

    logging.info(f"OCR —Ç–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {text[:500]}")  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏

    return text.strip()


# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ—Å—Ç–æ–≤
def process_test(file_path, language="ru"):
    try:
        ext = os.path.splitext(file_path)[1].lower()

        if ext == ".docx":
            text = read_docx(file_path)
        elif ext == ".pdf":
            text = read_pdf(file_path)
            if not text.strip():
                logging.warning("PDF —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º OCR")
                text = read_pdf_with_ocr(file_path)
        else:
            with open(file_path, "r", encoding="utf-8") as file:
                text = file.read()

        if not text.strip():
            raise ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")

        questions = parse_questions(text)

        if not questions:
            logging.error("–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤–æ–ø—Ä–æ—Å—ã!")
            raise ValueError("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–æ–≤")

        processed_questions = []
        for q in questions:
            if not q["answers"]:  # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ–≥–æ —Å –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
                correct_answer, wrong_answers = generate_answers(q["question"], q["tags"])
            else:  # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –µ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                correct_answer = q["answers"][0]
                wrong_answers = generate_wrong_answers(q["question"], correct_answer, q["tags"])

            processed_questions.append({
                "question": q["question"],
                "correct_answer": correct_answer,
                "wrong_answers": wrong_answers,
                "tags": q["tags"],
                "language": language
            })

        logging.info(f"DEBUG (–≥–æ—Ç–æ–≤—ã–π JSON):\n{json.dumps(processed_questions, indent=4, ensure_ascii=False)}")
        json_path = "output.json"
        with open(json_path, "w", encoding="utf-8") as json_file:
            json.dump(processed_questions, json_file, indent=4, ensure_ascii=False)

        return processed_questions
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ—Å—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ—Å—Ç–∞")


# FastAPI —Å–µ—Ä–≤–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ API
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –ò–ª–∏ —É–∫–∞–∂–∏ ["http://localhost:5176", "https://netlify-app-url"] –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
@app.get("/")
async def root():
    return {"status": "ok"}

@app.get("/get_questions")
async def get_questions():
    try:
        with open("output.json", "r", encoding="utf-8") as json_file:
            questions = json.load(json_file)
        return {"questions": questions}
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="–§–∞–π–ª —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")


@app.post("/process_test")
async def upload_file(file: UploadFile = File(...), language: str = "ru"):
    logging.info(f"–ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª: {file.filename}, —è–∑—ã–∫: {language}")
    try:
        file_path = f"temp_{file.filename}"
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        logging.info(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {file_path}")

        results = process_test(file_path, language)
        logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ, –≤–æ–ø—Ä–æ—Å–æ–≤: {len(results)}")

        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        try:
            os.remove(file_path)
            logging.info(f"–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª—ë–Ω: {file_path}")
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {file_path}: {e}")

        return {"questions": results}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞")
